{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oGayz-42sNzC"
      },
      "source": [
        "#### Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8hwjxQXIAEC",
        "outputId": "ac601b5c-4474-4dff-e742-924d41bd87d8"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "%pip install langchain\n",
        "%pip install openai\n",
        "%pip install PyPDF2\n",
        "%pip install pinecone-client\n",
        "%pip install tiktoken\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import os\n",
        "import tqdm\n",
        "import pinecone"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gHhU4dhk38-j"
      },
      "source": [
        "#### Enter API KEYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tHWiLLULIXfZ"
      },
      "outputs": [],
      "source": [
        "# Enter your API key & region from Pinecone. \n",
        "PINECONE_API_KEY = 'fd59ad27-4abe-4292-a743-7ef93e4d860e'\n",
        "PINECONE_API_ENV = 'us-west1-gcp-free'\n",
        "\n",
        "# Enter your API key from Openai. \n",
        "# Link to keys: https://platform.openai.com/account/billing/overview\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NbgyNzZb38-k"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdzpKnmfJUD2",
        "outputId": "0ec90d20-f76b-4563-cc48-cafbbd0d5beb"
      },
      "outputs": [],
      "source": [
        "# Locally upload PDF\n",
        "# Access to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X1_K4QIrsRzA"
      },
      "source": [
        "#### Load PDF documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y_tb0D40Lg9N"
      },
      "outputs": [],
      "source": [
        "# Location of the pdf file/files. \n",
        "reader = PdfReader('/content/gdrive/MyDrive/Notebooks/chatgpt/pdi_ce8.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FXDWhy0-LJ6n"
      },
      "outputs": [],
      "source": [
        "# Iterate through the PDF pages, extract the text and hold in a variable - raw_text\n",
        "raw_text = ''\n",
        "for i, page in enumerate(reader.pages):\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        raw_text += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ViTdyz7-38-l",
        "outputId": "d1af87d6-649e-49f9-b817-eeda4b4a65b9"
      },
      "outputs": [],
      "source": [
        "# Check the text - returns 200 characters\n",
        "raw_text[:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Brrbh2r38-l"
      },
      "outputs": [],
      "source": [
        "# Set the params for text spitter - RecursiveCharacterTextSplitter with an overlap of 100 between the documents to ensure context\n",
        "# This splits the raw text into documents based on words, sentences, paragraphs\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "documents = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg5SYlJK_gai",
        "outputId": "eaf1107b-6489-4ba8-e97f-25d842043da1"
      },
      "outputs": [],
      "source": [
        "# Should have 266 documents with 975 characters in first document\n",
        "print (f'You have {len(documents)} document(s) loaded')\n",
        "print (f'There are {len(documents[0])} characters in the first document')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2SJstYxx38-l"
      },
      "source": [
        "#### Create embeddings for storing vectors in Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3YM5EBQGLsWs"
      },
      "outputs": [],
      "source": [
        "# Embed - convert to vectors (266)\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zqhkec5INEh3"
      },
      "outputs": [],
      "source": [
        "# Connect to Pinecone and set namespace\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  \n",
        "    environment=PINECONE_API_ENV  \n",
        ")\n",
        "# index name must match index created in Pinecone\n",
        "index_name = 'pdi'\n",
        "# to make semantic searching easier add namespace\n",
        "namespace = 'CE_8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orQZ6dvf38-m"
      },
      "outputs": [],
      "source": [
        "# DO NOT execute this function. Not applicable to the free tier in Pinecone.\n",
        "# https://docs.pinecone.io/docs\n",
        "# The following example creates an index without a metadata configuration.\n",
        "# By default, Pinecone indexes all metadata.\n",
        "pinecone.create_index('pdi', \n",
        "                      dimension=1536, \n",
        "                      metric='cosine', \n",
        "                      pods=1, \n",
        "                      replicas=1, \n",
        "                      pod_type='p1.x1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h_g8HrrTNF8c"
      },
      "outputs": [],
      "source": [
        "# load up the embeddings into Pinecone index - namespace\n",
        "# Check in Pinecone - you should have 247 vectors\n",
        "docsearch = Pinecone.from_texts(documents, embeddings, index_name=index_name, namespace=namespace)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fT-dABSHNImu"
      },
      "source": [
        "#### Query 'documents'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L7VJCRxRNIHQ"
      },
      "outputs": [],
      "source": [
        "# Using llm.chain you can now query the document\n",
        "# chain_type=stuff \n",
        "# temperature=0 to cut down waffle\n",
        "llm = OpenAI(temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "euv1QxSKNUsa"
      },
      "outputs": [],
      "source": [
        "# Build query\n",
        "# Conduct a similarity search against vectors in Pinecone\n",
        "query = \"what is lazy conversion\"\n",
        "docs = docsearch.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7bS2sDQlNWiK",
        "outputId": "d1762708-0b1f-4210-d300-7df7917faeb5"
      },
      "outputs": [],
      "source": [
        "# Run question / query\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
